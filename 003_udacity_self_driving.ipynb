{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_udacity-self-driving.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONOFYC/h9oJGLLpmkJjlBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/pytorch_retinanet/blob/master/003_udacity_self_driving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH1Sj929WQ_b"
      },
      "source": [
        "# What GPU do we have ?\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4PPRrltWyCN"
      },
      "source": [
        "\n",
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34L5I9YsW0Gp"
      },
      "source": [
        "# Clone the RetinaNet Repo\n",
        "!git clone https://github.com/benihime91/pytorch_retinanet.git\n",
        "# install dependencies\n",
        "!pip install pytorch-lightning omegaconf wandb --quiet\n",
        "!pip install git+https://github.com/albumentations-team/albumentations --quiet\n",
        "!echo \"[   OK   ] Installed all depedencies \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-k1aK6mW2cW"
      },
      "source": [
        "#Update sys path to enclude the pytorch RetinaNet modules\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sys.path.append(\"/content/pytorch_retinanet/\")\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "!echo \"[   OK   ] Setup Done \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn_c_-WeW4iU"
      },
      "source": [
        "#Downloading data Udacity-self driving dataset from Roboflow\n",
        "#UPDATE THIS LINK - get our data from Roboflow\n",
        "#https://public.roboflow.com/object-detection/self-driving-car\n",
        "%cd /content\n",
        "!curl -L \"[ROBOFLOW DATA DOWNLOAD LINK]\" > roboflow.zip\n",
        "!unzip -qq roboflow.zip\n",
        "!rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFbwLeHKW_ey"
      },
      "source": [
        "#Set up paths \n",
        "\n",
        "#Path to where the Images are stored\n",
        "IMAGE_PATH = \"/content/export\"\n",
        "#Path where annotations are stored\n",
        "ANNOT_PATH = \"/content/export\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EbQyB7hXJQU"
      },
      "source": [
        "import pandas as pd\n",
        "from utils.pascal import convert_annotations_to_df\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "np.random.seed(123)\n",
        "\n",
        "\n",
        "def remove_invalid_annots(df):\n",
        "    \"\"\"\n",
        "    Removes annotations where xmax, ymax < xmin,ymin\n",
        "    from the given dataframe\n",
        "    \"\"\"\n",
        "    df = df[df.xmax > df.xmin]\n",
        "    df = df[df.ymax > df.ymin]\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    return df\n",
        "\n",
        "def split_dataframe(dataframe, split_size:float=0.3, seed=123):\n",
        "    \"\"\"\n",
        "    Splits a given pandas DataFrame object in `split_size`\n",
        "    \n",
        "    Args:\n",
        "        dataframe: a pandas DataFrame object\n",
        "        split_size: fraction size of the test dataframe\n",
        "        seed : a random seed to ensure reproducibility\n",
        "    \n",
        "    Returns :\n",
        "        1. train_df: a pandas DataFrame of size `(1-split_size)*len(dataframe)`\n",
        "        2. test_df : a pandas DataFrame of size `(split_size)*len(dataframe)`\n",
        "    \"\"\"\n",
        "    unique_ids = list(dataframe.filename.unique())\n",
        "    train_ids, test_ids = train_test_split(unique_ids, \n",
        "                                           shuffle=True, \n",
        "                                           random_state=seed, \n",
        "                                           test_size=split_size\n",
        "                                           )\n",
        "    \n",
        "    dataframe[\"split\"] = 0\n",
        "    \n",
        "    for i,idx in enumerate(tqdm(dataframe.filename.values)):\n",
        "        if idx in set(train_ids): \n",
        "            dataframe[\"split\"][i] = \"train\"\n",
        "        \n",
        "        elif idx in set(test_ids) : \n",
        "            dataframe[\"split\"][i] = \"test\"\n",
        "\n",
        "    #Create the training and test dataframes\n",
        "    df_train = dataframe.loc[dataframe[\"split\"] == \"train\"]\n",
        "    df_test = dataframe.loc[dataframe[\"split\"] == \"test\"]\n",
        "    #Reset indices and drop the redundant \"split\" column\n",
        "    df_train, df_test = df_train.reset_index(drop=True),df_test.reset_index(drop=True)\n",
        "    df_train.drop(columns=[\"split\"], inplace=True)\n",
        "    df_test.drop(columns=[\"split\"], inplace=True)\n",
        "\n",
        "    return df_train, df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kURLYLqtZdGS"
      },
      "source": [
        "#Create a pandas dataframe object from the xml files and filter the invalid annotations\n",
        "dataframe = remove_invalid_annots(convert_annotations_to_df(ANNOT_PATH, IMAGE_PATH, image_set=\"train\"))\n",
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmahMZDIZnuP"
      },
      "source": [
        "#Create train and test datasets\n",
        "train_df, test_df = split_dataframe(dataframe=dataframe, split_size=0.3)\n",
        "print(\"Num Training examples: \", len(train_df.filename.unique()), end=\"\\n\\n\")\n",
        "\n",
        "#Create test and validation datasets\n",
        "valid_df, test_df = split_dataframe(dataframe=test_df, split_size=0.5)\n",
        "print(\"Num Training examples: \", len(test_df.filename.unique()))\n",
        "print(\"Num Validation examples:\", len(valid_df.filename.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTtVnm1waB0z"
      },
      "source": [
        "#save dataframes to memory\n",
        "TRAIN_PATH = \"/content/train_data.csv\"\n",
        "TEST_PATH = \"/content/test_data.csv\"\n",
        "VALIDATION_PATH = \"/content/validation_data.csv\"\n",
        "\n",
        "\n",
        "train_df.to_csv(TRAIN_PATH, index=False)\n",
        "test_df.to_csv(TEST_PATH, index=False)\n",
        "valid_df.to_csv(VALIDATION_PATH, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTo-IRZDa120"
      },
      "source": [
        "from utils.pascal import generate_pascal_category_names\n",
        "from utils import visualize_boxes_and_labels_on_image_array as viz_bbs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Generate a lable map for categories\n",
        "LABEL_MAP = generate_pascal_category_names(dataframe)\n",
        "print(LABEL_MAP)\n",
        "\n",
        "\n",
        "def grab_bbs_(dataframe, index:int):\n",
        "    \"\"\"\n",
        "    Takes in a Pandas DataFrame and a index number\n",
        "    Returns filename of the image and all the bounding boxes and class_labels\n",
        "    corresponding the image that is at the given index\n",
        "    \"\"\"\n",
        "    assert index <= len(dataframe), f\"[  ERROR  ] Invalid index for dataframe with len: {len(dataframe)}\"\n",
        "    fname = dataframe.filename[index]\n",
        "    locs  = dataframe.loc[dataframe.filename == fname]\n",
        "    bbs   = locs[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    cls   = locs[\"labels\"].values\n",
        "    return fname, bbs, cls\n",
        "\n",
        "def load_image_from_data(dataframe, index):\n",
        "    \"\"\"\n",
        "    Loads in a image from the given dataframe at given index\n",
        "    Returns a PIL image object contraining all the bounding boxes over\n",
        "    the image\n",
        "    \"\"\"\n",
        "    image, boxes, clas = grab_bbs_(dataframe, index)\n",
        "    #load and normalize the image\n",
        "    image = Image.open(image)\n",
        "    image = np.array(image) / 255.\n",
        "    image = viz_bbs(image, boxes, scores=None, classes=clas, label_map=LABEL_MAP)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix30nnJkbtrk"
      },
      "source": [
        "image = load_image_from_data(train_df, index=10)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJY2dPNGb78c"
      },
      "source": [
        "image = load_image_from_data(test_df, index=100)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U6bnqsecFv1"
      },
      "source": [
        "from omegaconf import OmegaConf\n",
        "\n",
        "hparams = OmegaConf.load(\"/content/pytorch_retinanet/hparams.yaml\")\n",
        "\n",
        "hparams.dataset.kind = \"csv\"\n",
        "\n",
        "hparams.dataset.trn_paths   = TRAIN_PATH\n",
        "hparams.dataset.valid_paths = VALIDATION_PATH\n",
        "hparams.dataset.test_paths  = TEST_PATH\n",
        "hparams.model.num_classes = len(LABEL_MAP) - 1\n",
        "\n",
        "hparams.optimizer = {\n",
        "    \"class_name\": \"torch.optim.SGD\", \n",
        "    \"params\": {\n",
        "        \"lr\": 0.003,\n",
        "        \"momentum\": 0.9,\n",
        "        \"weight_decay\" : 0.001,\n",
        "        },\n",
        "    }\n",
        "\n",
        "print(OmegaConf.to_yaml(hparams))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMzm3gstcpZL"
      },
      "source": [
        "import time\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import *\n",
        "from pytorch_lightning.callbacks import *\n",
        "from model import RetinaNetModel, LogCallback\n",
        "\n",
        "# seed so that results are reproducible\n",
        "pl.seed_everything(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqBD7micu4O"
      },
      "source": [
        "#Logger\n",
        "#wandb API-KEY\n",
        "!wandb login \"[WANDB API-KEY]\"\n",
        "#Wandb project name\n",
        "PNAME = \"[WANDB PROJECT-NAME]\"\n",
        "LOGGER = WandbLogger(name=f\"{time.time()}\", anonymous=True, project=PNAME)\n",
        "\n",
        "#Learning-rate Logger to log the learning-rate to the logger\n",
        "LR_LOGGER = LearningRateLogger(logging_interval=\"step\")\n",
        "\n",
        "#Model Checkpoint Callback, this callback will save checkpoints \n",
        "#each time our val loss decreases\n",
        "fname =f\"/content/checkpoints/\"\n",
        "os.makedirs(fname, exist_ok=True)\n",
        "CHECKPOINT_CALLBACK = ModelCheckpoint(fname, mode=\"min\", monitor=\"val_loss\", save_top_k=3,)\n",
        "\n",
        "#callback for early-stopping\n",
        "EARLY_STOPPING_CALLBACK = EarlyStopping(mode=\"min\", monitor=\"val_loss\", patience=12, verbose=True)\n",
        "\n",
        "#instantiate LightningTrainer\n",
        "trainer = Trainer(\n",
        "    precision=16, \n",
        "    max_epochs=60,\n",
        "    gpus=1, \n",
        "    logger=[LOGGER],\n",
        "    early_stop_callback=EARLY_STOPPING_CALLBACK, \n",
        "    checkpoint_callback=CHECKPOINT_CALLBACK,\n",
        "    callbacks=[LogCallback(), LR_LOGGER], \n",
        "    weights_summary=None,\n",
        "    terminate_on_nan=True, \n",
        "    benchmark=True,\n",
        "    );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKuVX4GydL1G"
      },
      "source": [
        "#Instantiate lightning-module\n",
        "litModel = RetinaNetModel(hparams=hparams)\n",
        "#Start Train\n",
        "trainer.fit(litModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1P1sxrIdSX1"
      },
      "source": [
        "#Evaluations results on the test/ validation dataset(if test dataset is not given)\n",
        "#using COCO API\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpEA3n1-dVH7"
      },
      "source": [
        "import torch\n",
        "from retinanet import Retinanet\n",
        "\n",
        "PATH = f\"/content/trained_weights.pth\"\n",
        "torch.save(litModel.model.state_dict(), PATH)\n",
        "\n",
        "state_dict = torch.load(PATH)\n",
        "MODEL = Retinanet(num_classes=hparams.model.num_classes, backbone_kind=hparams.model.backbone_kind)\n",
        "MODEL.load_state_dict(state_dict)\n",
        "MODEL.to(\"cuda:0\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYrrZZXOdcWc"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_preds(path, threshold=0.6,):\n",
        "    \"\"\"\n",
        "    Generates predictions on the given image from the given path.\n",
        "    \"\"\"\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    INFER_TRANSFORMS = A.Compose([A.ToFloat(max_value=255.0, always_apply=True),\n",
        "                                  ToTensorV2(always_apply=True)\n",
        "                                  ])\n",
        "    \n",
        "    TENSOR_IMAGE = INFER_TRANSFORMS(image=image)[\"image\"].to(\"cuda:0\")\n",
        "    PREDICTIONS = MODEL.predict([TENSOR_IMAGE])\n",
        "    return PREDICTIONS[0]\n",
        "\n",
        "def detect(image_path, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Generate detections on the image that is present in \n",
        "    the given image path\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input Image\n",
        "        threshold: Score threshold to filter predictions\n",
        "        nms_threshold: NMS threshold\n",
        "\n",
        "    Returns: a PIL image containg the original Image and\n",
        "             bounding boxes draw over it.\n",
        "    \"\"\"\n",
        "    # Generate predictions for the given image\n",
        "    preds = get_preds(image_path, threshold,)\n",
        "    # print(preds)\n",
        "    # Filter predictions\n",
        "    boxes, labels, scores = preds[\"boxes\"], preds[\"labels\"], preds[\"scores\"]\n",
        "    mask   = scores > threshold\n",
        "    boxes  = boxes[mask]\n",
        "    labels = labels[mask]\n",
        "    scores = scores[mask]\n",
        "    return boxes.cpu().numpy(), labels.cpu().numpy(), scores.cpu().numpy()\n",
        "\n",
        "def draw_on_image(image_path, boxes, scores, classes, label_map=LABEL_MAP):\n",
        "    \"\"\"\n",
        "    Draw bounding box over the image at image path, with the scores and classes\n",
        "    Returns a PIL image object.\n",
        "    \n",
        "    Args: \n",
        "        image_path `(str)`: Path to the input Image\n",
        "        boxes `(List[N,4])`: absolute bouding box co-ordiates in the form `[xmin,ymin,xmax,ymax]`.\n",
        "        scores `(List[N])` : List containing the scores for each of the bounding box.\n",
        "        classes `(`List[N])`: List containing the class_labels for each of the bounding box.\n",
        "        label_map `(List[num_classes])`: List of the labels\n",
        "\n",
        "    Returns: \n",
        "        A PIL image object\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    image = np.array(image) / 255.\n",
        "    image = viz_bbs(image, boxes, scores=scores, classes=classes, label_map=LABEL_MAP)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OoJbfc-dnxN"
      },
      "source": [
        "#Path to the image\n",
        "image_path = test_df.filename[100]\n",
        "#generate predictions for the image\n",
        "boxes, labels, scores = detect(image_path, threshold=0.5)\n",
        "\n",
        "image = draw_on_image(image_path, boxes, scores, labels)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhwY9j-XU6HZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}