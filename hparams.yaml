# ============================================== #
# config file to instantiate the Lightning Model
# ============================================== #

# config paramters for the model backbone
model:
  backbone_kind: resnet50 # backbone of the model
  num_classes: 90 # number of classes (excluding the background class)
  freeze_bn: True # wether to freeze the backone of the model
  min_size: 800 # Size of the smallest side of the image during training
  max_size: 1600 # Maximum size of the side of the image during training

# Config parameters for the Daaset
dataset:
  # dataset kind one of [coco, pascal, csv]
  kind: false
  root_dir: false
  trn_paths: false
  valid_paths: false
  test_paths: false

# paramters for the pytroch DataLoader
dataloader:
  # Batch sizes
  train_bs: 2
  valid_bs: 30
  test_bs: 30
  args:
    # extra arguments to be passed to the dataloaders
    num_workers: 0
    pin_memory: True

# Albumentation transformations to use for the pascal dataset
# NOTE: these transformations are only supported for the dataset that is the
# specified csv format or for pascal dataset format
# These transformations are applied to the train dataset only
# no augmentation is applied to test, validation datasets
transforms:
  - class_name: albumentations.HorizontalFlip
    params:
      p: 0.5

# Optimzer to use for Training
optimizer:
  class_name: torch.optim.SGD
  params:
    lr: 0.001
    weight_decay: 0.001
    momentum: 0.9

# Scheduler to use for Training
# check : https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
# on how a scheduler is used in pytorch lightning
scheduler:
  class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
  params:
    mode: min
    factor: 0.1
    patience: 8

  interval: 1
  frequency: epoch
  monitor: val_loss # if monitor parameter is not required set this to be `false`
