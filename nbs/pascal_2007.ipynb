{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_pascal_2007.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kx-ROXRf8R0pC6i_qcAMmTrkHk8PNLO3",
      "authorship_tag": "ABX9TyNRU9XXT0PWejnbTDG8RE5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/pytorch_retinanet/blob/master/nbs/pascal_2007.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6qQWP6i0TCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What GPU do we have ?\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbvhLAldCPZx",
        "colab_type": "text"
      },
      "source": [
        "**Standard imports & setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DimpLe6l0ZV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKR4Mas0bts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies\n",
        "! pip install pytorch-lightning wandb\n",
        "! pip install git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM345So_0db0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab the Data\n",
        "! unzip -qq /content/drive/My\\ Drive/Pascal\\ 2007\\ Data/pascal_voc_2007_test.zip\n",
        "! unzip -qq /content/drive/My\\ Drive/Pascal\\ 2007\\ Data/pascal_voc_2007_train_val.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVy453Kj0ezz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the RetinaNet Repo:\n",
        "! git clone https://github.com/benihime91/pytorch_retinanet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXn7Cf1B0gUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKMiEqQnZiP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use wandb to track experiments : Comment this if not using wandb logger\n",
        "! wanbd login # a74f67fd5fae293e301ea8b6710ee0241f595a63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNIGOfxd07r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    LearningRateLogger,\n",
        ")\n",
        "\n",
        "from pytorch_retinanet.src.models import Retinanet\n",
        "from pytorch_retinanet.src.utils.eval_utils import CocoEvaluator\n",
        "from pytorch_retinanet.src.utils.eval_utils import get_coco_api_from_dataset\n",
        "from pytorch_retinanet.src.utils.general_utils import collate_fn\n",
        "from pytorch_retinanet import DetectionDataset, Visualizer\n",
        "\n",
        "pl.seed_everything(123)\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO0MlXYB__-A",
        "colab_type": "text"
      },
      "source": [
        "**Load in the Data:**  \n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/benihime91/bad475a40d16add314ba7be407803940/preprocess.ipynb) \n",
        "[preprocess_pascal.ipynb](https://github.com/benihime91/pytorch_retinanet/blob/master/nbs/preprocess_pascal.ipynb) : notebook to preprocess the `PascalVOC2007`data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEL2Ad5f2nag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/trn_data.csv')\n",
        "val_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/val_data.csv')\n",
        "tst_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/tst_data.csv')\n",
        "\n",
        "# Load in the Label Dict\n",
        "label_dict = pickle.load(open(\"/content/drive/My Drive/Pascal 2007 Data/names.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R9EZZH9-rYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df.head() # train dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g9OjRgQZuB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_df.head() # validation dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHK-ClX6ZwOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_df.head() # test dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEgZt63rZzx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict # a dictionary which stores the mapping of target_labels to class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLQ9dP3J29Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the visualizer\n",
        "viz = Visualizer(class_names=label_dict)\n",
        "\n",
        "def display_random_image(df: pd.DataFrame) -> None:\n",
        "    \"displays a radom Image from given dataframe\"\n",
        "    n = np.random.randint(0, len(df))\n",
        "    fname = df[\"filename\"][n]\n",
        "    boxes = df.loc[df[\"filename\"] == fname][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    labels = df.loc[df[\"filename\"] == fname][\"labels\"].values\n",
        "    viz.draw_bboxes(fname, boxes=boxes, classes=labels, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWzs5PpH3CEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the train set\n",
        "display_random_image(trn_df)\n",
        "display_random_image(trn_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-YWqtF-gf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the validation set\n",
        "display_random_image(val_df)\n",
        "display_random_image(val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wMRVsd-kUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the Test Dataset\n",
        "display_random_image(tst_df)\n",
        "display_random_image(tst_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWqI1lhh6cC1",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate `transforms`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV_zkqs_3GnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformations = [\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomSizedBBoxSafeCrop(600, 600, erosion_rate=0.2, p=0.3),\n",
        "    A.ToFloat(max_value=255.0, always_apply=True),\n",
        "    ToTensorV2(always_apply=True),\n",
        "]\n",
        "\n",
        "\n",
        "valid_transformations = [\n",
        "    A.ToFloat(max_value=255.0, always_apply=True),\n",
        "    ToTensorV2(always_apply=True),\n",
        "]\n",
        "\n",
        "# Transformations for train dataset\n",
        "trn_tfms = A.Compose(\n",
        "    train_transformations,\n",
        "    p=1.0,\n",
        "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),\n",
        ")\n",
        "\n",
        "# Transformations for validations & test dataset\n",
        "val_tfms = A.Compose(\n",
        "    valid_transformations,\n",
        "    p=1.0,\n",
        "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OZIC6bN6VQZ",
        "colab_type": "text"
      },
      "source": [
        "**Create `pl.LightningModule` instance :** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tw0PB184LEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectionModel(pl.LightningModule):\n",
        "    def __init__(self,model: nn.Module, hparams: argparse.Namespace) -> None:\n",
        "        super(DetectionModel, self).__init__()\n",
        "        self.model = model # model\n",
        "        self.hparams = hparams # hyperparameters\n",
        "        \n",
        "    @property\n",
        "    def num_batches(self) -> List[int]:\n",
        "        \"returns the number of batches in train, validaiton & test dataloader\"\n",
        "        return [len(self.hparams.train_dl), len(self.hparams.val_dl), len(self.hparams.test_dl)]\n",
        "    \n",
        "    # ---------------------------------------------------------------- #\n",
        "    # Configure Optimizer & Scheduler for the model\n",
        "    # ---------------------------------------------------------------- #\n",
        "    def configure_optimizers(self, *args, **kwargs):\n",
        "        # optimizer\n",
        "        self.optimizer = self.hparams.optimizer\n",
        "        # stepLrScheduler\n",
        "        self.scheduler = self.hparams.scheduler\n",
        "        return [self.optimizer], [self.scheduler]\n",
        "\n",
        "    # ---------------------------------------------------------------- #\n",
        "    # Train Logic:\n",
        "    # ---------------------------------------------------------------- #\n",
        "    def train_dataloader(self, *args, **kwargs):\n",
        "        return self.hparams.train_dl\n",
        "\n",
        "    def forward(self, xb, *args, **kwargs):\n",
        "        return self.model(xb)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        loss_dict = self.model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        return {\"loss\": losses, \"log\": loss_dict, \"progress_bar\": loss_dict}\n",
        "\n",
        "    # ---------------------------------------------------------------- #\n",
        "    # Validation Logic:\n",
        "    # ---------------------------------------------------------------- #\n",
        "    def val_dataloader(self, *args, **kwargs):\n",
        "        loader = self.hparams.val_dl\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.coco_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.coco_evaluator.update(res)\n",
        "        return {}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.coco_evaluator.accumulate()\n",
        "        self.coco_evaluator.summarize()\n",
        "        metric = self.coco_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"COCO_mAP\": metric}\n",
        "        return {\"val_loss\": metric, \"log\": logs,\"progress_bar\": logs,}\n",
        "    \n",
        "    # ---------------------------------------------------------------- #\n",
        "    # Test Logic:\n",
        "    # ---------------------------------------------------------------- #\n",
        "    def test_dataloader(self, *args, **kwargs):\n",
        "        loader = self.hparams.test_dl\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.test_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.test_evaluator.update(res)\n",
        "        return {}\n",
        "    \n",
        "    def test_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.test_evaluator.accumulate()\n",
        "        self.test_evaluator.summarize()\n",
        "        metric = self.test_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"COCO_mAP\": metric}\n",
        "        return {\"COCO_mAP\": metric, \"log\": logs, \"progress_bar\": logs,}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHUhONui6nd1",
        "colab_type": "text"
      },
      "source": [
        "**Some Helper Functions :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8geJ9CkJYEK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloaders(\n",
        "    trn_df: pd.DataFrame, # train DataFrame\n",
        "    val_df: pd.DataFrame, # valid DataFrame\n",
        "    tst_df: pd.DataFrame, # test DataFrame\n",
        "    trn_tfms: A.Compose, # albumentations transformations for train data\n",
        "    val_tfms: A.Compose, # albumentations transformations for validation & test data\n",
        "    trn_bs: int, # train batch_size\n",
        "    val_bs: int, # validation & test batch_size\n",
        "    ) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "\n",
        "    \"Returns DataLoaders from given dataframes\"\n",
        "    # Instatiate the Detections Datasets\n",
        "    trn_ds = DetectionDataset(trn_df, trn_tfms) # train dataset\n",
        "    val_ds = DetectionDataset(val_df, val_tfms) # validaition dataset\n",
        "    tst_ds = DetectionDataset(tst_df, val_tfms) # test dataset\n",
        "    \n",
        "    # Train Dataloader \n",
        "    trn_dl = DataLoader(trn_ds, batch_size=trn_bs, shuffle=True, collate_fn=collate_fn, pin_memory=True,)\n",
        "    # Validation Dataloader\n",
        "    val_dl = DataLoader(val_ds,batch_size=val_bs, shuffle=False, collate_fn=collate_fn, pin_memory=False,)\n",
        "    # Test Dataloader\n",
        "    tst_dl = DataLoader(tst_ds, batch_size=val_bs, shuffle=False, collate_fn=collate_fn, pin_memory=False)\n",
        "    # return dataloaders\n",
        "    return trn_dl, val_dl, tst_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWhfHHj95K4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(\n",
        "    lr: float, # learning_rate\n",
        "    num_epochs: int, # total number of epochs\n",
        "    nc: int, # number of classes\n",
        "    df_train: Union[pd.DataFrame, None] = None, # train DataFrame\n",
        "    df_val: Union[pd.DataFrame, None] = None, # Validaiton DataFrame\n",
        "    df_test: Union[pd.DataFrame, None] = None, # Test DataFrame\n",
        "    trn_tfms: Union[A.Compose, None] = None, # albumentations transformations for train data\n",
        "    val_tfms: Union[A.Compose, None] = None, # albumentations transformations for validation & test data\n",
        "    trn_bs: Union[int, None] = None, # train batch_size\n",
        "    val_bs: Union[int, None] = None, # validation & test batch_size\n",
        "    bkb: Union[str, None] = None, # name of the resnet based backbone\n",
        ") -> Tuple[pl.LightningModule, List[DataLoader], argparse.Namespace]:\n",
        "\n",
        "    \"\"\"\n",
        "    Creates lightning Module instance from given arguments\n",
        "\n",
        "    Returns:\n",
        "        1. pl_model (pl.LightningModule)  : a pl.LightningModule instance\n",
        "        2. dataloaders (List[Dataloader]) : list of train, val, test dataloaders\n",
        "        3. hparams ([argparse.Namespace]) : hyperparmeters\n",
        "    \"\"\"\n",
        "    # Instantiate RetinaNet Model\n",
        "    model = Retinanet(num_classes=nc, backbone_kind=bkb)\n",
        "    \n",
        "    # Instantiate in the DataLoaders\n",
        "    train_dl, val_dl, test_dl = get_dataloaders(df_train, df_val, df_test, trn_tfms, val_tfms, trn_bs, val_bs)\n",
        "    \n",
        "    # Instatiate Optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad] # trainable parameters\n",
        "    optimizer = optim.AdamW(params, lr, weight_decay=1e-02) # optimizer\n",
        "    \n",
        "    # Instantiate Scheduler\n",
        "    scheduler = {\n",
        "        \"scheduler\": optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=num_epochs, steps_per_epoch=len(train_dl)),\n",
        "        \"interval\": \"step\", # [one of step or epoch]\n",
        "        \"frequency\": 1,\n",
        "        }\n",
        "\n",
        "    # Create Config Dictionary:\n",
        "    conf_dict = {\n",
        "        \"train_dl\": train_dl, # train dataloader\n",
        "        \"val_dl\": val_dl,  # validation dataloader\n",
        "        \"test_dl\": test_dl, # test dataloader\n",
        "        \"iou_types\": [\"bbox\"], # for Ivaluation\n",
        "        \"optimizer\": optimizer, # optimizer\n",
        "        \"scheduler\": scheduler, # scheduler\n",
        "        } \n",
        "    \n",
        "    # Convert config dictionary to `argparse.Namespace` instance\n",
        "    hparams = argparse.Namespace(**conf_dict)\n",
        "\n",
        "    # Instantiate lightning module\n",
        "    pl_model = DetectionModel(model, hparams)\n",
        "    dataloaders = [train_dl, val_dl, test_dl] \n",
        "    \n",
        "    return pl_model, dataloaders, hparams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc_AgEbvYBMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_trainer(filepath: Union[str, None] = None, **kwargs) -> pl.Trainer:\n",
        "    \"Returns a pl.Trainer instance\"\n",
        "    \n",
        "    if filepath is None:\n",
        "        filepath = \"/content/drive/My Drive/pascal_checkpoints\" \n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "    # Wandb logger: assuming wandb is set-up [Optional]\n",
        "    wb_logger = WandbLogger(\n",
        "        name=f\"retinanet-pets-{time.strftime('%d-%m:::%I.%M.%S%p')}\",\n",
        "        project=\"pascal-2007\",\n",
        "        anonymous=\"allow\",\n",
        "    )\n",
        "\n",
        "    # Learning_rate logger to monitor learning_rate [Optional]\n",
        "    lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
        "\n",
        "    # checkpoint callback\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        mode=\"max\",\n",
        "        monitor=\"COCO_mAP\",\n",
        "        save_top_k=1,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    # early stopping callback\n",
        "    early_stopping_callback = EarlyStopping(mode=\"max\", monitor=\"COCO_mAP\", patience=5,)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = pl.Trainer(\n",
        "        logger=[wb_logger], # wandb logger\n",
        "        callbacks=[lr_logger], # callback to log the learning rate to wandb\n",
        "        num_sanity_val_steps=0, # no need to do sanity check\n",
        "        benchmark=True, # squeeze extra performance from the GPU\n",
        "        early_stop_callback=early_stopping_callback, # early stopping callback\n",
        "        checkpoint_callback=checkpoint_callback, # checkpoints the highest mAP model\n",
        "        terminate_on_nan=True, # Terminate if values become `nan`\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm-a42DY-7HI",
        "colab_type": "text"
      },
      "source": [
        "**Set Training Parameter sand Grab the `model` & `trainer`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPutRiTL7Als",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------------- #\n",
        "# Training Parameters :\n",
        "# ------------------------------- #\n",
        "TRAIN_BATCH_SIZE = 32 # Batch size for train dataset\n",
        "VALID_BATCH_SIZE = 32 # batch size for valid & test dataset\n",
        "LR = 4e-03 # learning_rate for Optimizer\n",
        "NUM_CLASSES = 20  # Pascal 2007 has 20 Classes\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "# Instantiate the model\n",
        "retinanet, dataloaders, conf_dict = get_model(\n",
        "    LR, # learning rate\n",
        "    NUM_EPOCHS, # total number of epochs\n",
        "    NUM_CLASSES, # total number of unique target classes\n",
        "    trn_df, # train dataframe\n",
        "    val_df, # validation dataframe\n",
        "    tst_df, # test dataframe\n",
        "    trn_tfms, # train transformations [albumentations]\n",
        "    val_tfms, # valid & test dataframe [albumentations]\n",
        "    trn_bs=TRAIN_BATCH_SIZE, # train batch_size\n",
        "    val_bs=VALID_BATCH_SIZE, # valid & test batch_size\n",
        "    bkb=\"resnet50\", # kind of resnet backbone\n",
        ")\n",
        "\n",
        "# Instantiate Trainer\n",
        "trainer = get_trainer(check_val_every_n_epoch=5, gpus=1, precision=16, gradient_clip_val=0.1, max_epochs=NUM_EPOCHS,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73_BgwVj6tY2",
        "colab_type": "text"
      },
      "source": [
        "**Train model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U09Swxi17-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit Model \n",
        "trainer.fit(retinanet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDaMutnjJ6Zt",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba5L5lkf68vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model on test dataloadet\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}